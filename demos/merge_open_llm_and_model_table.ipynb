{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNbl0CUuwaUVy1KnrJNaQW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas"],"metadata":{"id":"vuqp0XRVdVdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Vj9qThcdenj","executionInfo":{"status":"ok","timestamp":1739430141744,"user_tz":480,"elapsed":15514,"user":{"displayName":"Jikai Jin","userId":"04217813959834526607"}},"outputId":"3e35f6b2-c0e5-4452-bb07-0609fa75a855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["BASE_DIR = '/content/drive/MyDrive/LLM causality/'\n","TABLES_DIR = BASE_DIR + 'Tables/'"],"metadata":{"id":"KIxamK88dyHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","\n","\n","def merge_model_data(models_table_path, capability_path):\n","    # Read the CSV files into pandas DataFrames\n","    models_table = pd.read_csv(models_table_path)\n","    capability = pd.read_csv(capability_path)\n","\n","    # Process model names in capability.csv\n","    capability['Processed_Model'] = capability['fullname'].str.split('/').str[-1].str.lower()\n","\n","    # Process model names in models_table.csv\n","    models_table['Processed_Model'] = models_table['Playground'].str.split('/').str[-1].str.lower()\n","\n","    # Create all possible variations of model names in both dataframes\n","    def generate_variants(model_name):\n","        model_name = str(model_name)\n","        variants = set()\n","        variants.add(model_name)\n","        variants.add(model_name.replace(\"-\", \" \"))\n","        # Handle cases where some hyphens are replaced and some are not\n","        for i in range(model_name.count(\"-\")):\n","          new_name = model_name\n","          for j in range(i):\n","            new_name = new_name.replace(\"-\", \" \", 1)\n","          variants.add(new_name)\n","        return variants\n","\n","    capability['Model_Variants'] = capability['Processed_Model'].apply(generate_variants)\n","    models_table['Model_Variants'] = models_table['Processed_Model'].apply(generate_variants)\n","\n","\n","    #Explode the variants columns to create rows for each possible variant\n","    capability = capability.explode(\"Model_Variants\")\n","    models_table = models_table.explode(\"Model_Variants\")\n","\n","    # Merge the DataFrames based on the processed model names using all possible variants\n","    merged_df = pd.merge(capability, models_table, on='Model_Variants', how='inner')\n","\n","    # Select the desired columns and rename the 'Model_x' column to 'Model'\n","    merged_df = merged_df[['Model_x'] + [col for col in merged_df.columns if col not in ['Model_x', 'Model_y', 'Processed_Model_x', 'Processed_Model_y', \"Model_Variants_x\", \"Model_Variants_y\"]]]\n","    merged_df = merged_df.rename(columns={'Model_x': 'Model'})\n","\n","    return merged_df\n","\n","# Example usage (replace with your actual file paths):\n","merged_data = merge_model_data(TABLES_DIR + 'models_table.csv', TABLES_DIR + 'open_llm_leaderboard.csv')\n","len(merged_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFeJQoAbeJvr","executionInfo":{"status":"ok","timestamp":1739430319711,"user_tz":480,"elapsed":1210,"user":{"displayName":"Jikai Jin","userId":"04217813959834526607"}},"outputId":"7aa80a18-0fa4-4847-afed-994d65948e33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["164"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Remove duplicate rows based on the 'Model' column\n","merged_data = merged_data.drop_duplicates(subset=['Model'])\n","\n","# Save the filtered data to a new CSV file\n","merged_data.to_csv(TABLES_DIR + 'models_table_filtered.csv', index=False)\n"],"metadata":{"id":"TTnCIC_l6wEx"},"execution_count":null,"outputs":[]}]}